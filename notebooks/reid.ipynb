{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "reid.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-e0ba97b4",
   "language": "python",
   "display_name": "PyCharm (gcn)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZMRGRvCMDxUc",
    "colab_type": "code",
    "outputId": "f4186bbb-7e94-4caf-8cfa-9109ae713cac",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590746635876,
     "user_tz": -120,
     "elapsed": 3647,
     "user": {
      "displayName": "Fabien Benoist",
      "photoUrl": "",
      "userId": "01835534517613855526"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    }
   },
   "source": [
    "#Mount drive\n",
    "\n",
    "import os, sys\n",
    "\n",
    "class FileSystem:\n",
    "  def __init__(self, colab_dir=\"PersonTracking\", local_dir=\"./\", data_dir=\"data\"): # replace with dlav path\n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "    if (IN_COLAB):\n",
    "      from google.colab import drive\n",
    "      drive.mount('/gdrive')\n",
    "      self.root_dir = os.path.join(\"/gdrive/My Drive/\", colab_dir)\n",
    "    else:\n",
    "      self.root_dir = local_dir\n",
    "    self.data_dir = data_dir\n",
    "    self.change_directory = False\n",
    "\n",
    "  def data_path(self, name):\n",
    "    return os.path.join(self.data_dir, name) if self.change_directory else os.path.join(self.root_dir, self.data_dir, name)\n",
    "\n",
    "  def path(self, name):\n",
    "    return os.path.join(\"./\", name) if self.change_directory else os.path.join(\"./\", self.root_dir, name)\n",
    "\n",
    "  def cd(self):\n",
    "    %cd {self.root_dir}\n",
    "    %ls\n",
    "    self.change_directory = True\n",
    "\n",
    "fs = FileSystem()\n",
    "fs.cd()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nodiz/Desktop/PersonTracking\n",
      "Baseline.patch             \u001B[1m\u001B[36m__pycache__\u001B[m\u001B[m/\r\n",
      "\u001B[1m\u001B[36mDetectedImages\u001B[m\u001B[m/            \u001B[1m\u001B[36mdetLib\u001B[m\u001B[m/\r\n",
      "\u001B[1m\u001B[36mDetection\u001B[m\u001B[m/                 detect3000.py\r\n",
      "\u001B[1m\u001B[36mFrames\u001B[m\u001B[m/                    dr_utils.py\r\n",
      "\u001B[1m\u001B[36mInput-Output\u001B[m\u001B[m/              \u001B[1m\u001B[36moutput\u001B[m\u001B[m/\r\n",
      "LICENSE.md                 \u001B[1m\u001B[36mpic\u001B[m\u001B[m/\r\n",
      "\u001B[1m\u001B[36mMirkosREIDPlayground\u001B[m\u001B[m/      pippo3000.py\r\n",
      "README.md                  reid.ipynb\r\n",
      "\u001B[1m\u001B[36mVideo\u001B[m\u001B[m/                     reid3000.py\r\n",
      "VideoPersonTracking.ipynb  \u001B[1m\u001B[36mreidLib\u001B[m\u001B[m/\r\n",
      "\u001B[1m\u001B[36mvids\u001B[m\u001B[m/              \u001B[1m\u001B[36mtemp\u001B[m\u001B[m/\r\n",
      "\u001B[1m\u001B[36mWeightsDetection\u001B[m\u001B[m/          tryYolo.ipynb\r\n",
      "\u001B[1m\u001B[36mWeightsReid\u001B[m\u001B[m/\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q1sxhHfKHvxs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns \n",
    "sns.set()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MIhhmOM96e8z",
    "colab_type": "code",
    "outputId": "95567899-1e68-48d8-8116-d2d8eff319d3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590746642314,
     "user_tz": -120,
     "elapsed": 1257,
     "user": {
      "displayName": "Fabien Benoist",
      "photoUrl": "",
      "userId": "01835534517613855526"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "# Build model\n",
    "\n",
    "from reidLib.modeling.baseline import Baseline\n",
    "\n",
    "__file__ = fs.path('reidLib/modeling')\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "\n",
    "def build_model(num_classes):\n",
    "    #     model = Baseline(num_classes, cfg.MODEL.LAST_STRIDE, cfg.MODEL.PRETRAIN_PATH, cfg.MODEL.NECK, cfg.TEST.NECK_FEAT \\ after)\n",
    "    model = Baseline(num_classes, 1, \"WeightsReid/resnet50-19c8e357.pth\", 'bnneck', 'after', 'resnet50', 'imageNet')   # maybe try self instead of imageNet\n",
    "    return model\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = build_model(1041)  # 1041 identities in training dataset\n",
    "model.eval()  # evaluation mode\n",
    "#model=torch.load('WeightsReid/resnet50_ibn_a_center_param_120.pth')\n",
    "model.load_param('WeightsReid/WeightFab/center/resnet50_model_100.pth')\n",
    "model.to(device);"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'devie'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m./reidLib/modeling\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevie\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1041\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# 1041 identities in training dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# evaluation mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute 'devie'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "idsULim3D337",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Prepare tansform\n",
    "\n",
    "normalize_transform = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize([256, 128]),\n",
    "    T.ToTensor(),\n",
    "    normalize_transform\n",
    "])\n",
    "\n",
    "\n",
    "#Dataset  \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image Person ReID Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataset[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "def val_collate_fn(batch):\n",
    "    return torch.stack(batch, dim=0)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PXyqIfWljDH3",
    "colab_type": "code",
    "outputId": "f3dcb152-0ad4-44f7-fbef-e7eb78656f6c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590742872779,
     "user_tz": -120,
     "elapsed": 7305,
     "user": {
      "displayName": "Niccol√≤ Stefanini",
      "photoUrl": "",
      "userId": "02137552843712759139"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    }
   },
   "source": [
    "\"\"\"class Matcher():\n",
    "    def __init__(self, num_query, feat_norm='yes'):\n",
    "        self.num_query = num_query\n",
    "        self.feat_norm = feat_norm\n",
    "\n",
    "    def reset(self):\n",
    "        self.feats = []\n",
    "        self.pids = []\n",
    "\n",
    "    def update(self, output, ids):\n",
    "        feat, pid, camid = output\n",
    "        self.feats.append(feat)\n",
    "        self.pids.extend(np.asarray(ids))\n",
    "\n",
    "    def compute(self):\n",
    "        feats = torch.cat(self.feats, dim=0)\n",
    "        if self.feat_norm == 'yes':\n",
    "            print(\"The test feature is normalized\")\n",
    "            feats = torch.nn.functional.normalize(feats, dim=1, p=2)\n",
    "        # query\n",
    "        qf = feats[:self.num_query]\n",
    "        q_pids = np.asarray(self.pids[:self.num_query])\n",
    "        q_camids = np.asarray(self.camids[:self.num_query])\n",
    "        # gallery\n",
    "        gf = feats[self.num_query:]\n",
    "        g_pids = np.asarray(self.pids[self.num_query:])\n",
    "        g_camids = np.asarray(self.camids[self.num_query:])\n",
    "        m, n = qf.shape[0], gf.shape[0]\n",
    "        distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "                  torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "        distmat.addmm_(1, -2, qf, gf.t())\n",
    "        distmat = distmat.cpu().numpy()\n",
    "\n",
    "        num_q, num_g = distmat.shape\n",
    "\n",
    "        indices = np.argsort(distmat, axis=1)\n",
    "        matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n",
    "\"\"\""
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'class Matcher():\\n    def __init__(self, num_query, feat_norm=\\'yes\\'):\\n        self.num_query = num_query\\n        self.feat_norm = feat_norm\\n\\n    def reset(self):\\n        self.feats = []\\n        self.pids = []\\n        # self.camids = []\\n\\n    def update(self, output, ids):\\n        feat, pid, camid = output\\n        self.feats.append(feat)\\n        self.pids.extend(np.asarray(ids))\\n       # self.camids.extend(np.asarray(camid))\\n\\n    def compute(self):\\n        feats = torch.cat(self.feats, dim=0)\\n        if self.feat_norm == \\'yes\\':\\n            print(\"The test feature is normalized\")\\n            feats = torch.nn.functional.normalize(feats, dim=1, p=2)\\n        # query\\n        qf = feats[:self.num_query]\\n        q_pids = np.asarray(self.pids[:self.num_query])\\n        q_camids = np.asarray(self.camids[:self.num_query])\\n        # gallery\\n        gf = feats[self.num_query:]\\n        g_pids = np.asarray(self.pids[self.num_query:])\\n        g_camids = np.asarray(self.camids[self.num_query:])\\n        m, n = qf.shape[0], gf.shape[0]\\n        distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) +                   torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\\n        distmat.addmm_(1, -2, qf, gf.t())\\n        distmat = distmat.cpu().numpy()\\n        cmc, mAP = eval_func(distmat, q_pids, g_pids, q_camids, g_camids)\\n\\n        num_q, num_g = distmat.shape\\n        max_rank = num_g\\n\\n        indices = np.argsort(distmat, axis=1)\\n        matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\\n        return cmc, mAP\\n'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zv-BCVhkGWCw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Alahixandre\n",
    "def reid(gallery_path='pic/*', query_path='pic/*'):\n",
    "    \n",
    "    #Load images query \n",
    "    imgs_query = sorted(glob.glob(os.path.join(query_path, \"*.*\"))) \n",
    "    num_query = np.shape(imgs_query)[0]  # first x images in dataset\n",
    "\n",
    "    # Load images gallery\n",
    "    imgs_gallery = sorted(glob.glob(os.path.join(gallery_path, \"*.*\"))) #pic = gallery_path\n",
    "\n",
    "    imgs=imgs_query + imgs_gallery\n",
    "\n",
    "    #print([os.path.basename(x) for x in imgs[:num_query]])\n",
    "    #print([os.path.basename(x) for x in imgs[num_query:]])\n",
    "\n",
    "    # build dataset and dataloader\n",
    "    imdatas = ImageDataset(imgs, transform)\n",
    "    demo_loader = DataLoader(\n",
    "        imdatas, batch_size=np.shape(imgs)[0], shuffle=False, num_workers=4,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "\n",
    "\n",
    "    # model evaluation\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for batch in demo_loader:\n",
    "        batch = batch.to(device)\n",
    "        feat = model(batch) # (bs, 2048)\n",
    "        feat_norm = 1\n",
    "        if feat_norm:\n",
    "          feat = torch.nn.functional.normalize(feat, dim=1, p=2)\n",
    "        # query\n",
    "        qf = feat[:num_query]\n",
    "\n",
    "        # gallery\n",
    "        gf = feat[num_query:]\n",
    "\n",
    "        m, n = qf.shape[0], gf.shape[0]\n",
    "\n",
    "        distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "                  torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "\n",
    "        distmat.addmm_(1, -2, qf, gf.t())\n",
    "        distmat = distmat.cpu().numpy()\n",
    "\n",
    "        return distmat,\n",
    "    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FGZ6uYjp7iiy",
    "colab_type": "code",
    "outputId": "25fdfe8b-22c1-453d-9cf5-a02b6c4051a4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1590753110760,
     "user_tz": -120,
     "elapsed": 1818,
     "user": {
      "displayName": "Fabien Benoist",
      "photoUrl": "",
      "userId": "01835534517613855526"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    }
   },
   "source": [
    "distmat = reid(gallery_path='DetectedImages/MOT16-10-raw/*', query_path='YOLOv3-pedestrian/output/')\n",
    "print(distmat)\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2\n",
      "['MOT16-11-raw2- pedestrian1.jpg', 'MOT16-11-raw3- pedestrian1.jpg']\n",
      "['1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg', '1.jpg']\n",
      "torch.Size([21, 2048])\n",
      "2 19\n",
      "[[0.78506577 0.76209617 0.79826295 0.7718278  0.82034135 0.86445737\n",
      "  0.7821839  0.657313   0.7473388  0.79688156 0.64614594 0.74085414\n",
      "  0.803856   0.7613851  0.80956984 0.7239249  0.7281227  0.7654996\n",
      "  0.68638945]\n",
      " [0.94309735 0.9233998  0.88550365 0.925437   0.99413407 0.928411\n",
      "  0.94571376 0.703187   0.88762677 0.95068026 0.80814004 0.7869024\n",
      "  0.9521313  0.8593142  0.9758681  0.90749526 0.8401933  0.8944113\n",
      "  0.8356309 ]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nUGRF1mNEU4Y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AjzAJMKDEYxW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ebCsym9jELFt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}